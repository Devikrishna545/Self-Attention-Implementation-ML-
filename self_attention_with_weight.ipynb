{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaUYMC+rNK2SABjEdpD51s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devikrishna545/Self-Attention-Implementation-ML-/blob/main/self_attention_with_weight.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGsm44_sDjJL"
      },
      "outputs": [],
      "source": [
        "#self attention implementation with weights\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor([\n",
        "    [0.75, 0.42, 0.31],  # dream\n",
        "    [0.90, 0.50, 0.40],  # big\n",
        "    [0.20, 0.10, 0.05],  # and\n",
        "    [0.92, 0.53, 0.41],  # work\n",
        "    [0.35, 0.20, 0.15],  # for\n",
        "    [0.05, 0.90, 0.10],  # it (roughly orthogonal/away from others)\n",
        "])"
      ],
      "metadata": {
        "id": "yHfQQFyQOEqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=[\"Dream\",\"big\",\"and\",\"work\",\"for\",\"it\"]"
      ],
      "metadata": {
        "id": "iuMN5mZdOGcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#want to generate context vector of word  big\n",
        "x_2 = inputs[1]\n",
        "d_in = inputs.shape[1]\n",
        "d_out = 2 #context vector (hardcoded now)"
      ],
      "metadata": {
        "id": "4_6Dr1pQOMRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#randomly initializing Wq,Wk,Wv\n",
        "torch.manual_seed(123)\n",
        "W_query =torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
        "W_key =torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
        "W_value =torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)"
      ],
      "metadata": {
        "id": "v9vQa5zqO-uM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh9R30iIP9NP",
        "outputId": "91877c56-c9c7-4f1c-88b8-6ab6d90979ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0.2961, 0.5166],\n",
              "        [0.2517, 0.6886],\n",
              "        [0.0740, 0.8665]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf1P3A6pQCXD",
        "outputId": "b91ea4ba-c960-49a1-86ec-9c131d261402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0.1366, 0.1025],\n",
              "        [0.1841, 0.7264],\n",
              "        [0.3153, 0.6871]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLoCbcSdQGjz",
        "outputId": "a3240996-2331-48b9-8dda-ca697abb1900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0.0756, 0.1966],\n",
              "        [0.3164, 0.4017],\n",
              "        [0.1186, 0.8274]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for the word Big  in Q,K,V Space\n",
        "query_2 = x_2 @ W_query\n",
        "key_2 = x_2 @ W_key\n",
        "value_2 = x_2 @ W_value\n",
        "print(query_2)\n",
        "print(key_2)\n",
        "print(value_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zffO3omiQJ-e",
        "outputId": "13e9a2c1-ed64-48b5-8101-d9d1ad2e22e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4219, 1.1558])\n",
            "tensor([0.3411, 0.7303])\n",
            "tensor([0.2737, 0.7088])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating Q,K,V USING X,Wq,Wk,Wv\n",
        "\n",
        "Query = inputs @ W_query\n",
        "Key = inputs @ W_key\n",
        "Value = inputs @ W_value\n",
        "\n",
        "print(\"Keys shape\",Key.shape)\n",
        "print(\"Query shape\",Query.shape)\n",
        "print(\"Value shape\",Value.shape)\n",
        "\n",
        "print(Key)\n",
        "print(Query)\n",
        "print(Value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tbxUXxSRqFQ",
        "outputId": "c82cbfe5-73c7-454b-e107-7f31763e3922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys shape torch.Size([6, 2])\n",
            "Query shape torch.Size([6, 2])\n",
            "Value shape torch.Size([6, 2])\n",
            "tensor([[0.2775, 0.5950],\n",
            "        [0.3411, 0.7303],\n",
            "        [0.0615, 0.1275],\n",
            "        [0.3525, 0.7610],\n",
            "        [0.1319, 0.2842],\n",
            "        [0.2040, 0.7276]])\n",
            "tensor([[0.3507, 0.9452],\n",
            "        [0.4219, 1.1558],\n",
            "        [0.0881, 0.2155],\n",
            "        [0.4361, 1.1954],\n",
            "        [0.1651, 0.4485],\n",
            "        [0.2487, 0.7322]])\n",
            "tensor([[0.2264, 0.5727],\n",
            "        [0.2737, 0.7088],\n",
            "        [0.0527, 0.1209],\n",
            "        [0.2859, 0.7331],\n",
            "        [0.1075, 0.2733],\n",
            "        [0.3004, 0.4541]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Key corresponding to the second token and attention of the second token to itself\n",
        "keys_2 = Key[1]\n",
        "attention_score22 = query_2.dot(keys_2)\n",
        "print(attention_score22)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldDGLiB4SY_q",
        "outputId": "43a6a578-5415-4e8a-cdeb-e4600395338c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9880)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#all attention score for query_2(will not add up to one as we didnt normalise)\n",
        "attention_scores_2 = query_2 @Key.T\n",
        "print(attention_scores_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr1pF-gLUENr",
        "outputId": "fa3b203a-3930-41c1-9a37-685ef34d9fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.8047, 0.9880, 0.1733, 1.0283, 0.3842, 0.9271])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#attention scores without weights\n",
        "attention_scores = Query @Key.T\n",
        "print(attention_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "884Gl8BFUmHn",
        "outputId": "fbf6a6b5-3fc4-4da2-9030-dd37b5467e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6597, 0.8099, 0.1421, 0.8429, 0.3149, 0.7593],\n",
            "        [0.8047, 0.9880, 0.1733, 1.0283, 0.3842, 0.9271],\n",
            "        [0.1527, 0.1874, 0.0329, 0.1950, 0.0729, 0.1748],\n",
            "        [0.8323, 1.0218, 0.1792, 1.0635, 0.3973, 0.9588],\n",
            "        [0.3126, 0.3838, 0.0673, 0.3995, 0.1492, 0.3600],\n",
            "        [0.5046, 0.6195, 0.1086, 0.6449, 0.2409, 0.5835]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scale this by diving by square root of number of dimensions.(for word big)\n",
        "print(attention_scores_2)\n",
        "d_k=Key.shape[-1]\n",
        "attention_weights_2 = torch.softmax(attention_scores_2/d_k**0.5,dim=-1) #(sum of rows sums upto 1)\n",
        "print(attention_weights_2)\n",
        "print(d_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLhoLVmNVUE_",
        "outputId": "79249be5-be1d-4474-f6db-5d30b9321fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.8047, 0.9880, 0.1733, 1.0283, 0.3842, 0.9271])\n",
            "tensor([0.1729, 0.1969, 0.1107, 0.2025, 0.1284, 0.1886])\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#context vector corresponding to Big\n",
        "context_vector_2 = attention_weights_2 @ Value\n",
        "print(context_vector_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijZa9-MMWHVp",
        "outputId": "00e197f1-9cd6-459d-bbf9-d1b1dfd694b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2272, 0.5212])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#attenweight for all\n",
        "attention_weights = torch.softmax(attention_scores/d_k**0.5,dim=-1)\n",
        "print(attention_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWRcOC63dkPA",
        "outputId": "6b17a3ae-9fba-4653-c5be-96fd939d2653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1724, 0.1917, 0.1196, 0.1962, 0.1351, 0.1850],\n",
            "        [0.1729, 0.1969, 0.1107, 0.2025, 0.1284, 0.1886],\n",
            "        [0.1685, 0.1727, 0.1548, 0.1736, 0.1592, 0.1711],\n",
            "        [0.1730, 0.1978, 0.1090, 0.2037, 0.1272, 0.1892],\n",
            "        [0.1700, 0.1788, 0.1430, 0.1808, 0.1515, 0.1758],\n",
            "        [0.1715, 0.1860, 0.1296, 0.1893, 0.1423, 0.1813]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#context vector for all\n",
        "context_vectors = attention_weights @ Value\n",
        "print(context_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZSdDFByc81G",
        "outputId": "b513a885-3454-479a-fe97-f662d504ed30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2240, 0.5139],\n",
            "        [0.2272, 0.5212],\n",
            "        [0.2117, 0.4861],\n",
            "        [0.2278, 0.5225],\n",
            "        [0.2158, 0.4952],\n",
            "        [0.2205, 0.5057]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#In Python Class\n",
        "\n",
        "*   Version_1 shows taking random value  as parameters in forward pass\n",
        "*   Version_2  shows giving bias  with the weights in forward pass (In real     world scenarios we need to have such biases)\n"
      ],
      "metadata": {
        "id": "BI0CQHXf1Hlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making everything under python class\n",
        "import torch.nn as nn\n",
        "\n",
        "class SelfAttention_version1(nn.Module):\n",
        "    def __init__(self,d_in,d_out):\n",
        "        super().__init__()\n",
        "        self.W_query =nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
        "        self.W_key =nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
        "        self.W_value =nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
        "\n",
        "    def forward(self,x):\n",
        "      Query = inputs @ self.W_query\n",
        "      Key = inputs @ self.W_key\n",
        "      Value = inputs @ self.W_value\n",
        "\n",
        "      attention_scores = Query @Key.T\n",
        "      attention_weights = torch.softmax(attention_scores/d_k**0.5,dim=-1)\n",
        "      context_vectors = attention_weights @ Value\n",
        "      return context_vectors"
      ],
      "metadata": {
        "id": "EgY6SQOLiCr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "self_attention = SelfAttention_version1(d_in=3,d_out=2)\n",
        "print(self_attention(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jaFctNTyUSK",
        "outputId": "016a966b-e597-49d0-def1-135933dcb67e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2240, 0.5139],\n",
            "        [0.2272, 0.5212],\n",
            "        [0.2117, 0.4861],\n",
            "        [0.2278, 0.5225],\n",
            "        [0.2158, 0.4952],\n",
            "        [0.2205, 0.5057]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making everything under python class\n",
        "import torch.nn as nn\n",
        "\n",
        "class SelfAttention_version2(nn.Module):\n",
        "    def __init__(self,d_in,d_out,qkv_bias=False):\n",
        "        super().__init__()\n",
        "        self.W_query =nn.Linear(d_in,d_out,bias=qkv_bias)\n",
        "        self.W_key =nn.Linear(d_in,d_out,bias=qkv_bias)\n",
        "        self.W_value =nn.Linear(d_in,d_out,bias=qkv_bias)\n",
        "\n",
        "    def forward(self,x):\n",
        "      Query = inputs @ self.W_query.weight.T\n",
        "      Key = inputs @ self.W_key.weight.T\n",
        "      Value = inputs @ self.W_value.weight.T\n",
        "\n",
        "      attention_scores = Query @Key.T\n",
        "      attention_weights = torch.softmax(attention_scores/d_k**0.5,dim=-1)\n",
        "      context_vectors = attention_weights @ Value\n",
        "      return context_vectors"
      ],
      "metadata": {
        "id": "GUQs46bVy2gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "self_attention = SelfAttention_version2(d_in=3,d_out=2,qkv_bias=True)\n",
        "print(self_attention(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SZcKrQkzmXq",
        "outputId": "417b19f9-1e77-45be-ff43-e70445b827ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1048,  0.3039],\n",
            "        [-0.1065,  0.3039],\n",
            "        [-0.0995,  0.3038],\n",
            "        [-0.1066,  0.3040],\n",
            "        [-0.1012,  0.3038],\n",
            "        [-0.0934,  0.3073]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    }
  ]
}